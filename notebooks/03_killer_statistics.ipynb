{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Killer Statistics Analysis\n",
    "\n",
    "Comprehensive analysis of killer patterns and behaviors across CSI episodes.\n",
    "\n",
    "## Analysis Components:\n",
    "1. **Distribution Analysis**: How many killers per episode?\n",
    "2. **Speaking Patterns**: Do killers speak differently?\n",
    "3. **Temporal Analysis**: When do killers appear and reveal themselves?\n",
    "4. **Archetype Discovery**: Common killer behavior patterns\n",
    "5. **Statistical Testing**: Significance of behavioral differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path('../src').resolve()))\n",
    "\n",
    "# Import killer statistics analyzer\n",
    "from analysis.killer_statistics import KillerStatisticsAnalyzer\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Analyzer and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the analyzer\n",
    "analyzer = KillerStatisticsAnalyzer(data_dir=Path('../data/original'))\n",
    "\n",
    "# Get overall statistics\n",
    "overall_stats = analyzer.get_overall_statistics()\n",
    "\n",
    "print(\"Dataset Overview:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total episodes analyzed: {overall_stats['total_episodes']}\")\n",
    "print(f\"Episodes with identified killers: {overall_stats['episodes_with_killers']}\")\n",
    "print(f\"Total killers across all episodes: {overall_stats['total_killers']}\")\n",
    "print(f\"Average killers per episode: {overall_stats['avg_killers_per_episode']:.2f}\")\n",
    "print(f\"\\nKiller count distribution:\")\n",
    "for count, episodes in sorted(overall_stats['killer_distribution'].items()):\n",
    "    print(f\"  {count} killer(s): {episodes} episodes ({episodes/overall_stats['total_episodes']*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Killer Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize killer distributions\n",
    "fig = analyzer.plot_killer_distributions()\n",
    "\n",
    "# Additional summary\n",
    "print(\"\\nKey Insights:\")\n",
    "print(f\"• Average killer speaking ratio: {overall_stats['avg_killer_speaking_ratio']:.3f}\")\n",
    "print(f\"• Average killer word ratio: {overall_stats['avg_killer_word_ratio']:.3f}\")\n",
    "print(f\"• Average first appearance (normalized): {overall_stats['avg_killer_first_appearance']:.3f}\")\n",
    "print(f\"• Average dialogue spread: {overall_stats['avg_killer_spread']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Speaking Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze speaking patterns\n",
    "speaking_patterns = analyzer.analyze_speaking_patterns()\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Mean Sentences', 'Median Sentences', 'Std Dev', 'Mean Words', 'Median Words'],\n",
    "    'Killers': [\n",
    "        speaking_patterns['killer_sentences']['mean'],\n",
    "        speaking_patterns['killer_sentences']['median'],\n",
    "        speaking_patterns['killer_sentences']['std'],\n",
    "        speaking_patterns['killer_words']['mean'],\n",
    "        speaking_patterns['killer_words']['median']\n",
    "    ],\n",
    "    'Non-Killers': [\n",
    "        speaking_patterns['non_killer_sentences']['mean'],\n",
    "        speaking_patterns['non_killer_sentences']['median'],\n",
    "        speaking_patterns['non_killer_sentences']['std'],\n",
    "        speaking_patterns['non_killer_words']['mean'],\n",
    "        speaking_patterns['non_killer_words']['median']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Display with styling\n",
    "def highlight_differences(val):\n",
    "    if isinstance(val, (int, float)):\n",
    "        return 'font-weight: bold' if val > 50 else ''\n",
    "    return ''\n",
    "\n",
    "styled_df = comparison_df.style.format({\n",
    "    'Killers': '{:.1f}',\n",
    "    'Non-Killers': '{:.1f}'\n",
    "})\n",
    "\n",
    "display(HTML(\"<h3>Speaking Pattern Comparison</h3>\"))\n",
    "display(styled_df)\n",
    "\n",
    "# Statistical test results\n",
    "tests = speaking_patterns['statistical_tests']\n",
    "print(\"\\nStatistical Significance Tests (Mann-Whitney U):\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Sentence count difference:\")\n",
    "print(f\"  U-statistic: {tests['sentence_mann_whitney_u']:.2f}\")\n",
    "print(f\"  p-value: {tests['sentence_p_value']:.4f}\")\n",
    "print(f\"  Significant: {'YES ✓' if tests['sentence_significant'] else 'NO ✗'}\")\n",
    "print(f\"\\nWord count difference:\")\n",
    "print(f\"  U-statistic: {tests['word_mann_whitney_u']:.2f}\")\n",
    "print(f\"  p-value: {tests['word_p_value']:.4f}\")\n",
    "print(f\"  Significant: {'YES ✓' if tests['word_significant'] else 'NO ✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Temporal Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze temporal patterns\n",
    "temporal_patterns = analyzer.analyze_temporal_patterns()\n",
    "\n",
    "# Visualize temporal patterns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Appearance timing distribution\n",
    "appearance = temporal_patterns['appearance_analysis']\n",
    "ax = axes[0]\n",
    "timing_data = [\n",
    "    appearance['early_appearance_rate'] * 100,\n",
    "    appearance['middle_appearance_rate'] * 100,\n",
    "    appearance['late_appearance_rate'] * 100\n",
    "]\n",
    "colors = ['green', 'yellow', 'red']\n",
    "ax.pie(timing_data, labels=['Early (0-33%)', 'Middle (33-67%)', 'Late (67-100%)'],\n",
    "       colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "ax.set_title('When Killers First Appear', fontweight='bold')\n",
    "\n",
    "# Average positions\n",
    "ax = axes[1]\n",
    "positions = ['First\\nAppearance', 'Last\\nAppearance']\n",
    "values = [appearance['avg_first_appearance'], appearance['avg_last_appearance']]\n",
    "bars = ax.bar(positions, values, color=['lightgreen', 'lightcoral'])\n",
    "ax.set_ylabel('Normalized Position (0-1)')\n",
    "ax.set_title('Average Killer Appearance Positions', fontweight='bold')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "for bar, val in zip(bars, values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, val + 0.02,\n",
    "            f'{val:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Dialogue spread\n",
    "ax = axes[2]\n",
    "spread_data = [stats.killer_spread for stats in analyzer.killer_stats.values() if stats.killer_count > 0]\n",
    "ax.hist(spread_data, bins=15, color='purple', alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Dialogue Spread (0=concentrated, 1=throughout)')\n",
    "ax.set_ylabel('Number of Episodes')\n",
    "ax.set_title('Killer Dialogue Distribution', fontweight='bold')\n",
    "ax.axvline(x=appearance['avg_spread'], color='red', linestyle='--',\n",
    "           label=f'Mean: {appearance[\"avg_spread\"]:.2f}')\n",
    "ax.legend()\n",
    "\n",
    "plt.suptitle('Temporal Analysis of Killer Behavior', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Reveal analysis\n",
    "if 'reveal_analysis' in temporal_patterns and temporal_patterns['reveal_analysis']['episodes_with_reveals'] > 0:\n",
    "    reveal = temporal_patterns['reveal_analysis']\n",
    "    print(\"\\nKiller Reveal Analysis:\")\n",
    "    print(f\"  Episodes with clear reveals: {reveal['episodes_with_reveals']}\")\n",
    "    print(f\"  Average reveal position: {reveal['avg_reveal_position']:.2f}\")\n",
    "    print(f\"  Post-reveal dialogue ratio: {reveal['avg_post_reveal_dialogue']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Killer Archetype Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze killer archetypes\n",
    "archetypes = analyzer.analyze_killer_archetypes()\n",
    "\n",
    "if archetypes:\n",
    "    # Create archetype DataFrame\n",
    "    archetype_data = []\n",
    "    for archetype_name, data in archetypes.items():\n",
    "        archetype_data.append({\n",
    "            'Archetype': archetype_name.replace('_', ' ').title(),\n",
    "            'Count': data['count'],\n",
    "            'Percentage': f\"{data['percentage']:.1f}%\",\n",
    "            'Examples': ', '.join(data['example_episodes'])\n",
    "        })\n",
    "    \n",
    "    archetype_df = pd.DataFrame(archetype_data)\n",
    "    archetype_df = archetype_df.sort_values('Count', ascending=False)\n",
    "    \n",
    "    # Display archetype table\n",
    "    display(HTML(\"<h3>Killer Archetypes</h3>\"))\n",
    "    display(archetype_df.style.set_properties(**{'text-align': 'left'}))\n",
    "    \n",
    "    # Visualize archetype distribution\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    archetype_names = archetype_df['Archetype'].values\n",
    "    archetype_counts = archetype_df['Count'].values\n",
    "    \n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(archetype_names)))\n",
    "    bars = ax.bar(archetype_names, archetype_counts, color=colors, alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    ax.set_xlabel('Killer Archetype', fontsize=12)\n",
    "    ax.set_ylabel('Number of Episodes', fontsize=12)\n",
    "    ax.set_title('Distribution of Killer Archetypes', fontsize=14, fontweight='bold')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, archetype_counts):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nArchetype Descriptions:\")\n",
    "    print(\"• Verbose: Killers who talk significantly more than average\")\n",
    "    print(\"• Silent: Killers who speak very little\")\n",
    "    print(\"• Early Bird: Killers who appear in the first third of the episode\")\n",
    "    print(\"• Late Arrival: Killers who don't appear until the final third\")\n",
    "    print(\"• Consistent: Killers whose dialogue is spread throughout the episode\")\n",
    "    print(\"• Burst: Killers who speak in concentrated bursts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Killer vs Suspect Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare killers with suspects\n",
    "suspect_comparison = analyzer.compare_killers_vs_suspects()\n",
    "\n",
    "if suspect_comparison['suspects_available'] and suspect_comparison['comparison']:\n",
    "    comp = suspect_comparison['comparison']\n",
    "    \n",
    "    # Create comparison visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    categories = ['Killers', 'Suspects', 'Innocent']\n",
    "    values = [\n",
    "        comp['killer_avg_sentences'],\n",
    "        comp['suspect_avg_sentences'],\n",
    "        comp['innocent_avg_sentences']\n",
    "    ]\n",
    "    colors = ['crimson', 'orange', 'lightblue']\n",
    "    \n",
    "    bars = ax.bar(categories, values, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax.set_ylabel('Average Sentences per Character', fontsize=12)\n",
    "    ax.set_title('Speaking Frequency: Killers vs Suspects vs Innocent', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                f'{val:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Add statistical test result\n",
    "    p_value = comp['kruskal_wallis_p_value']\n",
    "    sig_text = f\"Kruskal-Wallis Test: p = {p_value:.4f}\"\n",
    "    if comp['significant_difference']:\n",
    "        sig_text += \" (Significant)\"\n",
    "    else:\n",
    "        sig_text += \" (Not Significant)\"\n",
    "    \n",
    "    ax.text(0.5, 0.95, sig_text, transform=ax.transAxes,\n",
    "            ha='center', va='top', fontsize=11, style='italic',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nStatistical Analysis:\")\n",
    "    print(f\"  Kruskal-Wallis H-statistic: {comp['kruskal_wallis_statistic']:.2f}\")\n",
    "    print(f\"  p-value: {p_value:.4f}\")\n",
    "    print(f\"  Significant difference between groups: {'YES ✓' if comp['significant_difference'] else 'NO ✗'}\")\n",
    "else:\n",
    "    print(\"Suspect data not available in this dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Baseline Prediction Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get baseline prediction accuracies\n",
    "baselines = analyzer.get_baseline_prediction_accuracy()\n",
    "\n",
    "# Create baseline comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "baseline_names = ['Random\\n(50/50)', 'Majority\\nClass', 'Most Common\\nKiller Count']\n",
    "baseline_values = [\n",
    "    baselines['random_baseline'],\n",
    "    baselines['majority_class_baseline'],\n",
    "    baselines['most_common_count_baseline']\n",
    "]\n",
    "\n",
    "colors = ['gray', 'lightcoral', 'lightgreen']\n",
    "bars = ax.bar(baseline_names, baseline_values, color=colors, alpha=0.7, edgecolor='black')\n",
    "\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Baseline Prediction Accuracies', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.3, label='Random chance')\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, baseline_values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "            f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nBaseline Details:\")\n",
    "print(f\"• Random baseline: Always 50% (coin flip)\")\n",
    "print(f\"• Majority class: Predict '{baselines['majority_class_prediction']}' for all episodes\")\n",
    "print(f\"• Most common count: Always predict {baselines['most_common_killer_count']} killer(s) per episode\")\n",
    "print(f\"\\nThese are the minimum accuracies that any ML model should beat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Episode-Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze specific episodes in detail\n",
    "episode_stats = []\n",
    "for stats in analyzer.killer_stats.values():\n",
    "    if stats.killer_count > 0:\n",
    "        episode_stats.append({\n",
    "            'Episode': stats.episode_id,\n",
    "            'Killers': stats.killer_count,\n",
    "            'Speaking Ratio': stats.killer_speaking_ratio,\n",
    "            'First Appear': stats.killer_first_appearance,\n",
    "            'Spread': stats.killer_spread\n",
    "        })\n",
    "\n",
    "episode_df = pd.DataFrame(episode_stats)\n",
    "\n",
    "# Find interesting episodes\n",
    "print(\"Interesting Episodes:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Most talkative killer\n",
    "most_talkative = episode_df.nlargest(3, 'Speaking Ratio')\n",
    "print(\"\\nMost Talkative Killers:\")\n",
    "for _, row in most_talkative.iterrows():\n",
    "    print(f\"  {row['Episode']}: {row['Speaking Ratio']:.3f} of all dialogue\")\n",
    "\n",
    "# Most silent killer\n",
    "most_silent = episode_df.nsmallest(3, 'Speaking Ratio')\n",
    "print(\"\\nMost Silent Killers:\")\n",
    "for _, row in most_silent.iterrows():\n",
    "    print(f\"  {row['Episode']}: {row['Speaking Ratio']:.3f} of all dialogue\")\n",
    "\n",
    "# Latest appearing killer\n",
    "latest_appearance = episode_df.nlargest(3, 'First Appear')\n",
    "print(\"\\nLatest First Appearances:\")\n",
    "for _, row in latest_appearance.iterrows():\n",
    "    print(f\"  {row['Episode']}: First appears at {row['First Appear']:.2f} position\")\n",
    "\n",
    "# Most concentrated dialogue\n",
    "most_concentrated = episode_df.nsmallest(3, 'Spread')\n",
    "print(\"\\nMost Concentrated Dialogue (burst speakers):\")\n",
    "for _, row in most_concentrated.iterrows():\n",
    "    print(f\"  {row['Episode']}: Spread of {row['Spread']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save comprehensive report\n",
    "output_dir = Path('../experiments/killer_analysis')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "report = analyzer.generate_report(save_path=output_dir / 'killer_statistics.json')\n",
    "\n",
    "# Create summary markdown\n",
    "summary_md = f\"\"\"\n",
    "# Killer Statistics Summary\n",
    "\n",
    "## Dataset Overview\n",
    "- **Total Episodes**: {overall_stats['total_episodes']}\n",
    "- **Episodes with Killers**: {overall_stats['episodes_with_killers']}\n",
    "- **Average Killers per Episode**: {overall_stats['avg_killers_per_episode']:.2f}\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "### Speaking Patterns\n",
    "- Killers speak **{speaking_patterns['killer_sentences']['mean']:.1f}** sentences on average\n",
    "- Non-killers speak **{speaking_patterns['non_killer_sentences']['mean']:.1f}** sentences on average\n",
    "- Statistical significance: **p = {speaking_patterns['statistical_tests']['sentence_p_value']:.4f}**\n",
    "\n",
    "### Temporal Patterns\n",
    "- Average first appearance: **{temporal_patterns['appearance_analysis']['avg_first_appearance']:.2f}** (normalized position)\n",
    "- Early appearance rate: **{temporal_patterns['appearance_analysis']['early_appearance_rate']*100:.1f}%**\n",
    "- Average dialogue spread: **{temporal_patterns['appearance_analysis']['avg_spread']:.2f}**\n",
    "\n",
    "### Baseline Accuracies\n",
    "- Random: **{baselines['random_baseline']:.3f}**\n",
    "- Majority Class: **{baselines['majority_class_baseline']:.3f}**\n",
    "- Most Common Count: **{baselines['most_common_count_baseline']:.3f}**\n",
    "\n",
    "## Implications for Neural Models\n",
    "1. Killer prediction is inherently challenging (baseline ~{baselines['majority_class_baseline']:.3f})\n",
    "2. Speaking patterns show {'significant' if speaking_patterns['statistical_tests']['sentence_significant'] else 'no significant'} differences\n",
    "3. Temporal patterns suggest killers {'appear early' if temporal_patterns['appearance_analysis']['avg_first_appearance'] < 0.4 else 'appear throughout'}\n",
    "4. Multiple archetypes exist, requiring flexible model representations\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(summary_md))\n",
    "\n",
    "# Save summary\n",
    "with open(output_dir / 'killer_summary.md', 'w') as f:\n",
    "    f.write(summary_md)\n",
    "\n",
    "print(f\"\\nResults saved to {output_dir}\")\n",
    "print(\"Files created:\")\n",
    "for file in output_dir.glob('*'):\n",
    "    print(f\"  • {file.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}